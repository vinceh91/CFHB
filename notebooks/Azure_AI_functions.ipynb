{"cells":[{"cell_type":"markdown","source":["#CFH - Customer Feedback Hub\n##Fonctions associÃ©es aux appels des cognitive services Azure"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d0a780fb-5c6d-4ae3-95ad-ae2766391cca"}}},{"cell_type":"code","source":["print('#'*80)\nimport requests, uuid, datetime\nimport pandas as pd\nimport numpy as np\nfrom io import StringIO, BytesIO\n\nprint('-'*80)\nprint('Starting - ' + str(datetime.datetime.now()))\nprint('-'*80)\n\n\n## API Traduction\ndef GetTranslations (text_to_translate, subscriptionKey, region, constructed_url ):\n    # Recuperer la traduction en anglais (par defaut)\n\theaders = {\n    'Ocp-Apim-Subscription-Key': subscriptionKey,\n    'Ocp-Apim-Subscription-Region' : region,\n    'Content-type': 'application/json',\n    'X-ClientTraceId': str(uuid.uuid4())\n    }\n\n\tbody = [{ 'text': text_to_translate}]\n\trequest = requests.post(constructed_url, headers=headers, json=body)\n\tresponse = request.json()    \n\n\treturn response\n\n\n## API Analysis\n\ndef GetKeyPrhase (text_to_analyse, lang , subscriptionKey, region, constructed_url ):\n    # Extractions des groupes nominaux principaux\n\theaders = {\n    'Ocp-Apim-Subscription-Key': subscriptionKey,\n    'Ocp-Apim-Subscription-Region' : region,\n    'Content-type': 'application/json',\n    'Accept' : 'application/json'    }\n\tbody = {'documents' : [{ 'id': '1', 'language' : lang, 'text' : text_to_analyse}] }\n\trequest = requests.post(constructed_url+'/keyPhrases', headers=headers, json=body)\n\tresponse = request.json()    \n    \n\treturn response\n\ndef GetSentiment (text_to_analyse, lang , subscriptionKey, region, constructed_url ):\n    # Extraction du sentiment du commentaire\n\theaders = {\n    'Ocp-Apim-Subscription-Key': subscriptionKey,\n    'Ocp-Apim-Subscription-Region' : region,\n    'Content-type': 'application/json',\n    'Accept' : 'application/json'    }\n\tbody = {'documents' : [{ 'id': '1', 'language' : lang, 'text' : text_to_analyse}] }\n\trequest = requests.post(constructed_url+'/sentiment', headers=headers, json=body)\n\tresponse = request.json()    \n    \n\treturn response\n\n\n## API Langage Understanding\n\ndef GetLuis(text_to_analyse, subscriptionKey, constructed_url ):\n    #cette fonction permet de classifier un texte -- nouvelle version\n    param = {'verbose' : 'true',\n             'subscription-key' : subscriptionKey,\n             'show-all-intents' : 'true',\n             'log' : 'true',\n             'query' : text_to_analyse}\n    request = requests.get(constructed_url, params = param)\n    response = request.json()        \n    return response\n\ndef LUIS_CFH(lang, text, key,apps_id):\n    #set on the good luis according to language\n    if len(text)>500:\n        return {'query' : text,\n                'prediction' :  {'topIntent' : 'test too long, not supported ',\n                                'intents' : {'None': {'score': 1},\n                                             'General POSITIVE comment': {'score': 0.},\n                                             'EV Charging': {'score': 0.},\n                                             'Lubricants': {'score': 0.},\n                                             'Total Assistance': {'score': 0.},\n                                             'Pellets': {'score': 0.},\n                                             'Fuel Quality': {'score': 0.},\n                                             'Toilets': {'score': 0.},\n                                             'Safety': {'score': 0.},\n                                             'General NEGATIVE comment': {'score': 0.},\n                                             'Fleet Cards': {'score': 0.},\n                                             'Waiting Time': {'score': 0.},\n                                             'Coffee and Sandwiches': {'score': 0.},\n                                             'Total wash': {'score': 0.},\n                                             'Heating Fuel': {'score': 0.},\n                                             'Price': {'score': 0.},\n                                             'LPG/CNG': {'score': 0.},\n                                             'AdBlue': {'score': 0.},\n                                             'Offers': {'score': 0.},\n                                             'Total Club': {'score': 0.},\n                                             'Cleanliness': {'score': 0.},\n                                             'Welcome': {'score': 0.}},\n                                             'entities': {}}}\n    elif lang =='fr':  \n        url = 'https://westeurope.api.cognitive.microsoft.com/luis/prediction/v3.0/apps/'+apps_id[lang]+'/slots/production/predict'\n        return GetLuis(text,key,url)\n    elif lang == 'nl':\n         url = 'https://westeurope.api.cognitive.microsoft.com/luis/prediction/v3.0/apps/'+apps_id[lang]+'/slots/production/predict'\n         return GetLuis(text,key,url)\n    elif lang == 'en':\n         url = 'https://westeurope.api.cognitive.microsoft.com/luis/prediction/v3.0/apps/'+apps_id[lang]+'/slots/production/predict'\n         return GetLuis(text,key,url)\n    else:\n        return {'query' : text,\n                'prediction' :  {'topIntent' : 'language not supported',\n                                'intents' : {'None': {'score': 1},\n                                             'General POSITIVE comment': {'score': 0.},\n                                             'EV Charging': {'score': 0.},\n                                             'Lubricants': {'score': 0.},\n                                             'Total Assistance': {'score': 0.},\n                                             'Pellets': {'score': 0.},\n                                             'Fuel Quality': {'score': 0.},\n                                             'Toilets': {'score': 0.},\n                                             'Safety': {'score': 0.},\n                                             'General NEGATIVE comment': {'score': 0.},\n                                             'Fleet Cards': {'score': 0.},\n                                             'Waiting Time': {'score': 0.},\n                                             'Coffee and Sandwiches': {'score': 0.},\n                                             'Total wash': {'score': 0.},\n                                             'Heating Fuel': {'score': 0.},\n                                             'Price': {'score': 0.},\n                                             'LPG/CNG': {'score': 0.},\n                                             'AdBlue': {'score': 0.},\n                                             'Offers': {'score': 0.},\n                                             'Total Club': {'score': 0.},\n                                             'Cleanliness': {'score': 0.},\n                                             'Welcome': {'score': 0.}},\n                                             'entities': {}}}\n\n\n\ndef GetSuggestedAnswer(lang, sentiment, prio, connect):\n    #cette fonction permet de selectionner la bonne reponse suggeree \n    try:\n        blob_service_client = BlobServiceClient.from_connection_string(connect['string'])\n        blob_client = blob_service_client.get_blob_client(container=connect['container'], blob=\"suggested_answer.csv\")\n        my_string = str( blob_client.download_blob().readall() ,'latin-1')\n        data = StringIO(my_string) \n        df = pd.read_csv(data, sep = \";\", decimal = \",\")  \n        return str(df.suggested.loc[(df.language == lang) & (df.sentiment_min <=  sentiment) & (df.sentiment_max > sentiment) & (df.topic == prio)].iloc[0])\n    except Exception as ex:\n        return \"Exceptation - \" + str(ex)\n\n# fonctions -------------------------------------------------------------------\n\ndef GetTranslations_multi (data_id_text, subscriptionKey, region, constructed_url ):\n    #recuperer la langue et la traduction de ZCL par batch\n\theaders = {'Ocp-Apim-Subscription-Key': subscriptionKey,\n               'Ocp-Apim-Subscription-Region' : region,\n                'Content-type': 'application/json'    }\n\tbody = data_id_text[[\"id\",\"text\"]].to_dict(orient= \"reccords\")\n\n\trequest = requests.post(constructed_url, headers=headers, json=body)\n\tresponse = request.json()   \n    \n\tmalist = []\n\tfor item in response:\n\t\tmalangue = str(item['detectedLanguage']['language'])  #str= error mgmnt\n\t\tmatrad = str(item['translations'][0]['text'])         #str= error mgmnt\n\t\tmalist.append({'language' : malangue, 'translation' : matrad})\n\t\tdel [matrad,malangue]\n        \n\treturn pd.DataFrame(malist)\n\ndef GetKeyPrhase_multi (id_lang_text_df, subscriptionKey, region, constructed_url ):\n    #recuperer les KeyPhrasees de ZCL par batch\n\theaders = {'Ocp-Apim-Subscription-Key': subscriptionKey,\n               'Ocp-Apim-Subscription-Region' : region,\n               'Content-type': 'application/json',\n               'Accept' : 'application/json'    }\n\tbody = {'documents' : id_lang_text_df.to_dict(orient= \"reccords\") }\n\trequest = requests.post(constructed_url+'/keyPhrases',\n                         headers=headers, \n                         json=body)\n\tresponse = request.json()        \n\treturn response\n\ndef GetSentiment_multi (id_lang_text_df, subscriptionKey, region, constructed_url ):\n     #recuperer les KeyPhrasees de ZCL par bactch\n\theaders = {'Ocp-Apim-Subscription-Key': subscriptionKey,\n               'Ocp-Apim-Subscription-Region' : region,\n               'Content-type': 'application/json',\n               'Accept' : 'application/json'}\n\tbody = {'documents' : id_lang_text_df.to_dict(orient= \"reccords\") }\n\trequest = requests.post(constructed_url+'/sentiment', \n                         headers=headers, \n                         json=body)\n\tresponse = request.json()        \n\treturn response\n\n\ndef GetSuggested_multi(df_in, connect):\n    #recuperer les reponse preformattee par bactch\n    blob_service_client = BlobServiceClient.from_connection_string(connect['string'])\n    blob_client = blob_service_client.get_blob_client(container=connect['container'], blob=\"suggested_answer.csv\")\n    my_string = str( blob_client.download_blob().readall() ,'latin-1')\n    data = StringIO(my_string) \n    df = pd.read_csv(data, sep = \";\", decimal = \",\")  \n\n    df_out = df_in.merge(df, \n                             left_on = ['language','Priorite'],\n                             right_on = ['language','topic'],\n                             how = 'left')\n    df_out = df_out.loc[((df_out.sentiment_min < df_out.Sentiment)&(df_out.sentiment_max > df_out.Sentiment)) | \n            (df_out.Sentiment.isna() ) |\n            (df_out.Priorite.isna()  ) |\n            (~df_out.language.isin(['en','fr','nl']))]\n\n    del [ df_out['sentiment_min'], df_out['sentiment_max'], df_out['topic'] ]\n    df_out = df_out.drop_duplicates(['id'], keep= 'first')\n    \n    return df_out\n\n# fonction consolidee ---------------------------------------------------------\n    \ndef TheVoice_multi(df_in,\n                   Key_TT, reg_TT, Url_TT,\n                   Key_TA, reg_TA, Url_TA,\n                   Key_LU, apps_id,\n                   connect):\n    #analyse d'un df sur l'ensemble des appels \n    #verif du fichier reÃ§u\n    try:\n        df = df_in[[\"id\",\"text\"]]\n        df = df.loc[ ~ df.text.isin( ['nan', 'NaN', np.nan, np.NaN])]\n        df = df.loc[df.text.apply(len)>5]\n    except Exception as ex:\n        return \"DataFrame format error, need id and text cols - \" + str(ex)\n    #traduction\n    try :\n        temp = GetTranslations_multi(df, Key_TT, reg_TT, Url_TT)\n        df_out = pd.concat([df.reset_index(),temp], axis = 1)\n        df_out['analysed_lang'] = 'en'\n        del temp\n    except Exception as ex:\n        return \"Translation Error - \" + str(ex)\n    #KeyPhrase\n    try:\n        temp = GetKeyPrhase_multi(df_out[[\"id\",\"analysed_lang\",\"translation\"]].rename(\n                columns={'translation':'text','analysed_lang':'language'}),\n                        Key_TA, reg_TA, Url_TA )\n        df_out = pd.concat([df_out,\n                            pd.DataFrame(temp['documents'])['keyPhrases']], \n                            axis = 1)\n        del temp\n    except Exception as ex:\n        return \"KeyPhrase Error - \" + str(ex)\n    #Sentiment\n    try:\n        temp = GetSentiment_multi(df_out[[\"id\",\"language\",\"text\"]],\n                        Key_TA , reg_TA, Url_TA)\n        df_out = pd.concat([df_out,\n                            pd.DataFrame(temp['documents'])['score']], \n                            axis = 1)\n        del temp\n    except Exception as ex:\n        return \"Sentiment Error - \" + str(ex)\n    #Reponse\n    try:\n        df_out[\"Priorite\"] = ''\n        df_out[\"Priorite score\"] = np.nan\n        df_out[\"LUIS\"] = ''\n        for i in range(len(df_out)):\n            try:\n                temp = LUIS_CFH(df_out.language.iloc[i], df_out.text.iloc[i], Key_LU, apps_id)\n            except Exception as ex:\n                print('LUIS query error' + str(ex) )\n                \n            temp = eval(\"[{'intent':\"+str(temp['prediction']['intents'])[1:-2].replace(\": {'score':\",\", 'score' : \").replace(\"},\",\"},{'intent':\")+\"}]\")\n            df_out[\"LUIS\"].iloc[i] = str(temp)\n            df_out[\"Priorite\"].iloc[i] = temp[0]['intent']\n            df_out[\"Priorite score\"].iloc[i] = temp[0]['score']\n    except Exception as ex:\n        return \"LUIS process error - \" + str(ex) + ' - ' + str(i) + ' - ' + str(temp)\n    \n    df_out = GetSuggested_multi(df_out, connect)   \n    \n    del [df_out['text'], df_out['index'] ]\n    return df_in.merge(df_out.rename(columns={'score' : 'Sentiment'}), left_on = 'id', right_on = 'id', how = 'left' ).copy()\n\n\ndef TheVoice_multi_lines(df_in,\n                   Key_TT, reg_TT, Url_TT,\n                   Key_TA, reg_TA, Url_TA,\n                   Key_LU, apps_id,\n                   connect):\n    #analyse ligne par ligne d'un df sur l'ensemble des appls\n    #verif du fichier reÃ§u\n    try:\n        df = df_in[[\"id\",\"text\"]]\n        df = df.loc[ ~ df.text.isin( ['nan', 'NaN', np.nan, np.NaN])]\n        df = df.loc[df.text.apply(len)>5]\n    except Exception as ex:\n        return \"DataFrame format error, need id and text cols - \" + str(ex)\n    #traduction\n    df['language'] =np.nan\n    df['translation'] = np.nan\n    df['analysed_lang'] = 'en'\n    df['keyPhrases'] = np.nan\n    df['Sentiment'] = np.nan\n    df[\"Priorite\"] = ''\n    df[\"Priorite score\"] = np.nan\n    df[\"LUIS\"] = ''\n    for i in range(len(df)):\n        try:\n            temp = GetTranslations(df.text.iloc[i] ,Key_TT, reg_TT, Url_TT)[0]\n            df[\"language\"].iloc[i]=str(temp['detectedLanguage']['language'])\n            df[\"translation\"].iloc[i]=str(temp['translations'][0]['text'])\n            del temp\n        except Exception as ex:\n            print( \"Translation lines error - \" + str(ex) + \" line : \" + str(i))\n        \n        try:\n            df[\"keyPhrases\"].iloc[i] = GetKeyPrhase(df.translation.iloc[i],\n                              df.analysed_lang.iloc[i],\n                              Key_TA, reg_TA,\n                              Url_TA)['documents'][0]['keyPhrases']\n        except Exception as ex:\n            print( \"KeyPhrases lines error - \" + str(ex) + \" line : \" + str(i))\n        \n        try:\n            df[\"Sentiment\"].iloc[i] = GetSentiment(df.text.iloc[i],\n                                      df.language.iloc[i],\n                                      Key_TA, reg_TA,\n                                      Url_TA)['documents'][0]['score']\n        except Exception as ex:\n            print( \"Sentiment lines error - \" + str(ex) + \" line : \" + str(i))\n\n\n        try:\n            temp = LUIS_CFH(df.language.iloc[i], df.text.iloc[i][:495], Key_LU, apps_id)\n        except Exception as ex:\n                print('LUIS query error' + str(ex) )\n        try:        \n            temp = eval(\"[{'intent':\"+str(temp['prediction']['intents'])[1:-2].replace(\": {'score':\",\", 'score' : \").replace(\"},\",\"},{'intent':\")+\"}]\")\n            df[\"LUIS\"].iloc[i] = str(temp)\n            df[\"Priorite\"].iloc[i] = temp[0]['intent']\n            df[\"Priorite score\"].iloc[i] = temp[0]['score']\n            del temp\n        except Exception as ex:\n            return \"LUIS process error - \" + str(ex) + ' - ' + str(i)\n    \n    df = GetSuggested_multi(df, connect)   \n    \n    del [df['text'] ]\n    return df_in.merge(df.rename(columns={'score' : 'Sentiment'}), left_on = 'id', right_on = 'id', how = 'left' ).copy()\n\n\nprint('#'*80)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e3918b1-c91b-41b6-a178-327cd72c99ff"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Azure_AI_functions","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2047508133846409}},"nbformat":4,"nbformat_minor":0}
